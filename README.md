**An interactive data science project analyzing COVID-19 research trends through the CORD-19 dataset, featuring comprehensive visualizations and a web-based dashboard.**

---

## ğŸ“‹ Table of Contents

- [ğŸ¯ Project Overview](#-project-overview)
- [ğŸ”¬ Analysis Goals](#-analysis-goals)
- [ğŸ“Š Key Findings](#-key-findings)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ› ï¸ Installation](#ï¸-installation)
- [ğŸ“ˆ Usage](#-usage)
- [ğŸ¨ Features](#-features)
- [ğŸ“¸ Screenshots](#-screenshots)
- [ğŸ”§ Technical Details](#-technical-details)
- [ğŸ“š Dataset Information](#-dataset-information)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)
- [ğŸ‘¨â€ğŸ’» Author](#-author)
- [ğŸ™ Acknowledgments](#-acknowledgments)

---

## ğŸ¯ Project Overview

The **CORD-19 Research Analysis Dashboard** is a comprehensive data science project that explores the landscape of COVID-19 research through interactive visualizations and statistical analysis. Built as a learning exercise to demonstrate fundamental data science skills, this project transforms raw research metadata into actionable insights about global pandemic research trends.

### ğŸŒŸ What This Project Accomplishes

- **Analyzes 1000,000+ research papers** from the CORD-19 dataset
- **Identifies publication trends** during the COVID-19 pandemic
- **Maps research landscape** across journals, authors, and institutions
- **Provides interactive exploration** through a web-based dashboard
- **Demonstrates end-to-end** data science workflow

---

## ğŸ”¬ Analysis Goals

This project was designed with specific learning and analytical objectives:

### ğŸ“ **Educational Goals**
- Master fundamental data science techniques (cleaning, exploration, visualization)
- Learn to build interactive web applications using Streamlit
- Practice working with large, real-world datasets
- Develop skills in data storytelling and presentation
- Create a portfolio-worthy project demonstrating technical competency

### ğŸ” **Research Questions**
1. **How did COVID-19 research publication patterns change over time?**
   - When did research output peak?
   - What was the publication velocity during different pandemic phases?

2. **Which journals and institutions led COVID-19 research efforts?**
   - What are the top-contributing academic journals?
   - How diverse is the research landscape?

3. **What research topics and themes dominated the literature?**
   - What keywords appear most frequently in titles?
   - How do research focuses vary over time?

4. **What are the characteristics of COVID-19 research papers?**
   - How long are abstracts typically?
   - What's the distribution of paper lengths and complexity?

5. **How can we make research discovery more accessible?**
   - Can we build tools to help researchers find relevant papers?
   - How can visualization improve understanding of research trends?

### ğŸ¯ **Technical Objectives**
- Implement complete data science pipeline (ETL â†’ Analysis â†’ Visualization â†’ Deployment)
- Build scalable, maintainable code following best practices
- Create interactive, user-friendly data exploration tools
- Demonstrate proficiency with Python data science ecosystem
- Deploy a functional web application

---

## ğŸ“Š Key Findings

My analysis revealed fascinating insights about COVID-19 research:

### ğŸ“ˆ **Publication Trends**
- **Explosive Growth**: Research output increased by over **2000%** from 2019 to 2020
- **Peak Period**: Maximum publication rate occurred in **mid-2020** during initial pandemic response
- **Sustained Interest**: Research remained elevated through 2021-2022

### ğŸ“° **Leading Journals**
- **medRxiv** and **bioRxiv** dominated preprint publications
- Traditional journals like **Nature**, **Science**, and **NEJM** published key breakthrough papers
- Rapid publication timelines emphasized urgency of research dissemination

### ğŸ”¤ **Research Focus Areas**
- **Clinical Terms**: "patients", "clinical", "treatment" most frequent
- **Viral Focus**: "coronavirus", "sars-cov-2", "covid-19" dominated titles  
- **Medical Emphasis**: Strong focus on medical interventions and patient outcomes

### ğŸ“„ **Paper Characteristics**
- **Abstract Length**: Average of **250 words** (longer than typical pre-pandemic papers)
- **Rapid Publication**: Shortened review cycles during pandemic peak
- **International Collaboration**: Increased multi-institutional authorship

---

## ğŸš€ Quick Start

Get the dashboard running in 3 simple steps:

```bash
# 1. Clone the repository
git clone https://github.com/ByteCortex00/Frameworks_Assignment.git
cd CORD19_Analysis

# 2. Install dependencies
pip install -r requirements.txt

# 3. Launch the dashboard
streamlit run streamlit_app.py
```

**ğŸ“ Then navigate to:** `http://localhost:8501`

**Note**: Download the dataset separately (see [Installation](#ï¸-installation) section)

---

## ğŸ“ Project Structure

```
CORD19_Analysis/
â”‚
â”œâ”€â”€ ğŸ“Š streamlit_app.py           # Main interactive dashboard
â”œâ”€â”€ ğŸ“‹ requirements.txt           # Python package dependencies
â”œâ”€â”€ ğŸ“– README.md                  # This comprehensive guide
â”‚
â”œâ”€â”€ ğŸ“ analysis/                  # Core analysis scripts
â”‚   â”œâ”€â”€ part1_exploration.py      # Initial data exploration
â”‚   â”œâ”€â”€ part2_cleaning.py         # Data cleaning & preprocessing
â”‚   â”œâ”€â”€ part3_analysis.py         # Statistical analysis & visualization
â”‚   â””â”€â”€ run_pipeline.py           # Complete analysis pipeline
â”‚
â”œâ”€â”€ ğŸ“ data/                      # Data directory (create this)
â”‚   â”œâ”€â”€ metadata.csv              # CORD-19 dataset (download required)
â”‚   â””â”€â”€ metadata_cleaned.csv      # Processed dataset (generated)
â”‚
â”œâ”€â”€ ğŸ“ plots/                     # Generated visualizations
â”‚   â”œâ”€â”€ publications_by_year.png
â”‚   â”œâ”€â”€ top_journals.png
â”‚   â”œâ”€â”€ word_frequency.png
â”‚   â”œâ”€â”€ title_wordcloud.png
â”‚   â””â”€â”€ abstract_length_distribution.png
|   â”œâ”€â”€ source_distribution.png


## ğŸ› ï¸ Installation

### Prerequisites

- **Python 3.7+** ([Download Python](https://www.python.org/downloads/))
- **Git** ([Download Git](https://git-scm.com/downloads))
- **4GB+ RAM** (for dataset processing)
- **2GB+ disk space** (for dataset storage)

### Step 1: Clone Repository

```bash
git clone https://github.com/ByteCortex00/Frameworks_Assignment.git
cd CORD19_Analysis
```

### Step 2: Create Virtual Environment (Recommended)

```bash
# Create virtual environment
python -m venv cord19_env

# Activate virtual environment
# On Windows:
cord19_env\Scripts\activate
# On macOS/Linux:
source cord19_env/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Download Dataset

1. **Visit Kaggle Dataset**: [CORD-19 Research Challenge](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)
2. **Create Kaggle Account** (free registration required)
3. **Download `metadata.csv`** only (~2GB file)
4. **Place file** in the `data/` directory (create folder if needed)

### Step 5: Verify Installation

```bash
python -c "import pandas, streamlit, plotly; print('âœ… All packages installed successfully!')"
```

---

## ğŸ“ˆ Usage

### ğŸ–¥ï¸ **Interactive Dashboard**

Launch the main dashboard for interactive exploration:

```bash
streamlit run streamlit_app.py
```

**Dashboard Features:**
- **Sidebar Filters**: Year range, journal selection, abstract filtering
- **Multiple Tabs**: Timeline, journals, words, characteristics, data explorer
- **Real-time Updates**: All visualizations update based on your filters
- **Data Export**: Download filtered datasets as CSV

### ğŸ” **Individual Analysis Scripts**

Run specific analysis components:

```bash
# Basic data exploration
python analysis/part1_exploration.py

# Data cleaning and preparation  
python analysis/part2_cleaning.py

# Generate all visualizations
python analysis/part3_analysis.py

# Complete pipeline
python analysis/run_pipeline.py
```

### ğŸ“Š **Jupyter Notebooks** (Optional)

For deeper exploration:

```bash
jupyter notebook notebooks/exploratory_analysis.ipynb
```

---

## ğŸ¨ Features

### ğŸ›ï¸ **Interactive Dashboard**

| Feature | Description |
|---------|-------------|
| **ğŸ“… Timeline Analysis** | Interactive year-over-year publication trends with growth rates |
| **ğŸ“° Journal Explorer** | Top publishing journals with customizable display options |
| **ğŸ”¤ Word Frequency** | Most common title words with adjustable word counts |
| **ğŸ“„ Paper Analytics** | Abstract/title length distributions and statistics |
| **ğŸ” Data Browser** | Search, filter, and export functionality |

### ğŸ“Š **Static Visualizations**

- **Publication Timeline**: Bar charts showing research output over time
- **Journal Rankings**: Horizontal bar charts of top contributors
- **Word Clouds**: Visual representation of common research terms
- **Distribution Plots**: Statistical analysis of paper characteristics
- **Growth Analysis**: Year-over-year percentage changes

### ğŸ› ï¸ **Technical Features**

- **Efficient Data Processing**: Optimized pandas operations for large datasets
- **Caching**: Streamlit caching for improved dashboard performance
- **Error Handling**: Comprehensive error messages and fallback options
- **Responsive Design**: Mobile-friendly dashboard layout
- **Export Options**: CSV download functionality for all filtered data



## ğŸ”§ Technical Details

### **Data Processing Pipeline**

1. **Data Ingestion**
   - Load 10000000 + research paper metadata
   - Handle various file encodings and formats
   - Memory-efficient chunk processing

2. **Data Cleaning**
   - Remove duplicates and invalid entries
   - Standardize date formats and text encoding
   - Handle missing values with appropriate strategies

3. **Feature Engineering**
   - Extract publication years from timestamps
   - Calculate word counts for abstracts and titles
   - Create categorical variables for analysis

4. **Analysis & Visualization**
   - Statistical summaries and trend analysis
   - Interactive plotting with Plotly
   - Word frequency analysis with text processing

### **Technology Stack**

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Data Processing** | pandas, NumPy | Large dataset manipulation |
| **Visualization** | Plotly, Matplotlib, Seaborn | Interactive and static charts |
| **Web Framework** | Streamlit | Dashboard deployment |
| **Text Analysis** | WordCloud, Collections | Natural language processing |
| **Development** | Python 3.7+, Git | Core development tools |

### **Performance Optimizations**

- **Streamlit Caching**: `@st.cache_data` for expensive operations
- **Data Filtering**: Efficient pandas operations for real-time updates
- **Memory Management**: Selective column loading and data chunking
- **Lazy Loading**: On-demand visualization generation

---

## ğŸ“š Dataset Information

### **CORD-19 Dataset Overview**

The COVID-19 Open Research Dataset (CORD-19) is a comprehensive collection of scholarly articles about COVID-19, SARS-CoV-2, and related coronaviruses.

| Attribute | Details |
|-----------|---------|
| **Size** | ~1000,000 research papers |
| **Time Period** | 1900 - Present (focus on 2020-2022) |
| **Sources** | PubMed, PMC, WHO, bioRxiv, medRxiv |
| **File Size** | ~2GB (metadata only) |
| **Update Frequency** | Weekly (historical dataset) |

### **Key Metadata Fields**

- **`title`**: Paper title
- **`abstract`**: Paper abstract text
- **`authors`**: Author list
- **`journal`**: Publication venue
- **`publish_time`**: Publication date
- **`doi`**: Digital Object Identifier
- **`pmcid`**: PubMed Central ID
- **`pubmed_id`**: PubMed ID

### **Data Quality Notes**

- **Missing Data**: Some papers lack abstracts (~30%) or publication dates (~15%)
- **Duplicates**: Minimal after preprocessing
- **Quality**: High-quality academic sources with peer review
- **Coverage**: Global research with emphasis on English-language publications

---

## ğŸ¤ Contributing

I welcome contributions to improve this analysis! Here's how you can help:

### **Types of Contributions**

- ğŸ› **Bug Reports**: Found an issue? Open a GitHub issue
- ğŸ’¡ **Feature Requests**: Ideas for new analysis or visualizations
- ğŸ“ **Documentation**: Improve README, add tutorials, or create guides
- ğŸ”§ **Code Improvements**: Optimize performance or add new features
- ğŸ“Š **Analysis Extensions**: New research questions or methodologies

### **How to Contribute**

1. **Fork the repository**
2. **Create feature branch**: `git checkout -b feature/new-analysis`
3. **Make your changes** with clear, documented code
4. **Add tests** if applicable
5. **Update documentation** as needed
6. **Submit pull request** with detailed description

### **Development Setup**

```bash
# Clone your fork
git clone https://github.com/ByteCortex00/Frameworks_Assignment.git

# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python -m pytest tests/

# Run linting
flake8 analysis/ streamlit_app.py
```

### **Contribution Guidelines**

- Follow PEP 8 style guidelines
- Write clear commit messages
- Include docstrings for new functions
- Add unit tests for new features
- Update README if needed

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### **What this means:**

- âœ… **Commercial Use**: You can use this code for commercial projects
- âœ… **Modification**: You can modify and distribute the code
- âœ… **Distribution**: You can distribute the original or modified code
- âœ… **Private Use**: You can use the code for private projects
- â— **Attribution Required**: You must include the original license

### **Dataset License**

The CORD-19 dataset is provided by the Allen Institute for AI under specific terms. Please review the [dataset license](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) before use.

---

## ğŸ‘¨â€ğŸ’» Author

**Peter Waweru Njuguna**

- ğŸ™ **GitHub**: [ByteCortex00](https://https://github.com/ByteCortex00)
- ğŸ’¼ **LinkedIn**: 
- ğŸ“§ **Email**: njungush444@gmail.com
- ğŸŒ **Portfolio**: [peternjuguna.netlify.app](https://peternjuguna.netlify.app/)

### **About This Project**

This project was developed as part of a data science learning journey, focusing on:
- Real-world dataset analysis
- Interactive web application development  
- Data visualization best practices
- End-to-end project management

**ğŸ¯ Skills Demonstrated:**
- Python programming and data science libraries
- Statistical analysis and visualization
- Web development with Streamlit
- Project documentation and presentation
- Git version control and collaboration

---

## ğŸ™ Acknowledgments

### **Data Sources**
- **Allen Institute for AI** - CORD-19 dataset creation and maintenance
- **Kaggle** - Dataset hosting and accessibility
- **Research Community** - Contributing papers and maintaining open science

### **Technical Inspiration**
- **Streamlit Team** - Excellent documentation and examples
- **Plotly Community** - Interactive visualization techniques
- **Pandas Community** - Data processing methodologies


### **Special Thanks**
- Course instructors and mentors for guidance
- Open source community for tools and libraries

---

## ğŸ“ Support & Contact

### **Getting Help**

- ğŸ“– **Documentation**: Check this README and inline code comments
- ğŸ› **Issues**: [Open a GitHub issue](https://github.com/ByteCortex00/Frameworks_Assignment/issues) for bugs or questions
- ğŸ’¬ **Discussions**: Use [GitHub Discussions]for general questions
- ğŸ“§ **Direct Contact**: Email for urgent issues or collaboration

### **Frequently Asked Questions**

**Q: The dashboard won't load my data**
A: Ensure `metadata.csv` is in the `data/` folder and you have sufficient RAM (4GB+).

**Q: Can I use a subset of the data?**
A: Yes! You can modify the loading code to read only the first N rows for testing.

**Q: How do I add new visualizations?**
A: Add new functions to the analysis scripts and integrate them into the Streamlit app tabs.

**Q: Can I deploy this dashboard online?**
A: Yes! Streamlit offers free hosting at [Streamlit Cloud](https://streamlit.io/cloud).

---

## ğŸš€ What's Next?

### **Planned Enhancements**

- ğŸ¤– **Machine Learning**: Add topic modeling and clustering analysis
- ğŸŒ **Geographic Analysis**: Map research contributions by country/institution
- ğŸ“Š **Advanced Analytics**: Citation analysis and research impact metrics
- ğŸ”— **API Integration**: Connect to live research databases
- ğŸ“± **Mobile Optimization**: Enhanced mobile dashboard experience

### **Learning Extensions**

- ğŸ§  **Deep Learning**: Implement paper recommendation systems
- ğŸ•¸ï¸ **Network Analysis**: Author collaboration networks
- ğŸ“ˆ **Time Series**: Advanced temporal pattern analysis
- ğŸ¯ **A/B Testing**: Dashboard feature optimization

---

**â­ If you find this project helpful, please give it a star on GitHub!**

**ğŸ”„ Found an issue or have a suggestion? I'd love to hear from you!**

---

*Last updated: September 2025*
*Version: 1.0.0*